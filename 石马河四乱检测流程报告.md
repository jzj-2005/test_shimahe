# 石马河四乱检测流程与步骤报告

## 一、项目背景

### 1.1 项目概述

石马河四乱检测系统是基于无人机巡检技术和深度学习算法的智能化水利监管系统。该系统采用YOLOv11x深度学习模型，通过无人机搭载高清摄像头进行石马河流域的航拍巡检，自动识别河道违法建筑、非法排污、违规种植、垃圾堆放等"四乱"问题，并精确计算违规目标的地理坐标，实现了水利巡检的智能化、精准化和高效化。

### 1.2 核心功能

- **自动目标检测**：采用YOLOv11x高精度检测算法，支持违建、植被、棚屋、垃圾堆放等多类别目标识别
- **精确定位**：自动将检测目标的像素坐标转换为CGCS2000地理坐标（国家标准），定位精度可达米级
- **双模式运行**：支持离线视频处理和实时流处理两种工作模式
- **智能数据融合**：集成SRT字幕、MQTT位姿数据和OCR视频识别三种数据源
- **可视化输出**：生成CSV结构化数据、检测截图、交互式地图和GeoJSON格式文件

### 1.3 技术优势

| 技术指标 | 性能表现 |
|---------|---------|
| 检测精度 | 置信度可达85%以上 |
| 定位精度 | 米级精度（<5米偏差） |
| 处理速度 | 支持跳帧加速，可处理25fps视频流 |
| 目标类别 | 支持11种违规目标类别 |
| 数据输出 | CSV、GeoJSON、图片、交互式地图 |

---

## 二、系统架构

### 2.1 技术架构

```
┌─────────────────────────────────────────────────────────────┐
│                    无人机巡检系统架构                         │
└─────────────────────────────────────────────────────────────┘

[数据采集层]
    ├── 无人机视频源（MP4文件/RTSP实时流）
    ├── 飞行位姿数据（SRT字幕/MQTT消息）
    └── OCR视频识别（备用数据源）
              ↓
[数据同步层]
    ├── 时间戳对齐（精度<100ms）
    ├── 帧位姿匹配
    └── 数据缓存队列
              ↓
[目标检测层]
    ├── YOLOv11x深度学习模型
    ├── 多类别目标识别
    └── 置信度筛选
              ↓
[坐标转换层]
    ├── 相机成像模型
    ├── GSD地面分辨率计算
    ├── 像素坐标→地理坐标转换
    └── 四角点坐标计算
              ↓
[结果输出层]
    ├── CSV结构化报告
    ├── 检测目标截图
    ├── GeoJSON地理数据
    └── 交互式Web地图
```

### 2.2 技术栈

| 技术组件 | 版本/说明 |
|---------|----------|
| 编程语言 | Python 3.8+ |
| 深度学习框架 | PyTorch (CUDA 11.8+) |
| 目标检测模型 | Ultralytics YOLOv11x |
| OCR识别引擎 | PaddleOCR |
| 视频处理 | FFmpeg + OpenCV |
| 实时通信 | Paho-MQTT |
| 地理信息 | GeoJSON + Leaflet |

### 2.3 工作模式对比

| 特性 | 离线视频处理模式 | 实时流处理模式 |
|------|----------------|---------------|
| **适用场景** | 算法验证、效果测试、历史视频分析 | 现场巡检、实时监控 |
| **数据源** | 本地MP4视频文件 + SRT字幕 | RTSP视频流 + MQTT位姿数据 |
| **时间同步** | 精确(<100ms) | 实时同步 |
| **处理速度** | 可跳帧加速（1-5倍速） | 必须实时处理 |
| **优势** | 可重复测试、结果稳定、支持批处理 | 即时反馈、无需存储大量视频 |
| **启动方式** | `run_video.bat` | `run_realtime.py` |

---

## 三、四乱检测流程

### 3.1 离线视频处理流程（推荐用于常规巡检）

#### 流程图

```
[步骤1] 数据准备
    └── 导入无人机录制的MP4视频文件
         ↓
[步骤2] SRT字幕提取
    └── 使用FFmpeg自动从视频中提取SRT字幕文件
    └── 备用：如无字幕轨道，启用OCR模式识别OSD
         ↓
[步骤3] 位姿数据解析
    └── 解析SRT文件，提取每帧的GPS坐标、飞行高度、姿态角度
         ↓
[步骤4] 视频逐帧解码
    └── 读取视频帧（支持跳帧加速）
         ↓
[步骤5] 时间戳精确同步
    └── 将视频帧与位姿数据按时间戳精确匹配（误差<100ms）
         ↓
[步骤6] YOLO目标检测
    └── 对每一帧进行深度学习检测
    └── 识别违建、垃圾、棚屋等违规目标
    └── 置信度筛选（默认阈值0.25）
         ↓
[步骤7] 像素坐标→地理坐标转换
    └── 基于相机成像模型和飞行位姿
    └── 计算检测框四个角点的CGCS2000坐标（WGS84→CGCS2000）
    └── 计算目标中心GPS坐标
         ↓
[步骤8] 结果输出
    └── 生成CSV结构化报告
    └── 保存检测目标截图
    └── 记录处理日志
```

#### 详细步骤说明

**步骤1：数据准备**
- 将无人机录制的视频文件放入 `data/input/videos/` 目录
- 确保视频格式为MP4，分辨率为5472×3648（或实际拍摄分辨率）
- 建议视频文件命名规范：`石马河_河段名称_日期.MP4`

**步骤2：SRT字幕提取**
- 系统自动检测视频是否包含字幕轨道
- 使用FFmpeg提取字幕到临时目录 `data/temp/srt/`
- 如果无字幕轨道，自动切换到OCR模式

**步骤3：位姿数据解析**
- 解析SRT文件中的时间码和GPS数据
- 提取关键信息：
  - GPS坐标（纬度、经度）
  - 相对高度（米）
  - 飞行姿态（俯仰角、偏航角、滚转角）
  - 时间戳（毫秒级）

**步骤4：视频逐帧解码**
- 使用OpenCV读取视频帧
- 支持跳帧处理（配置 `frame_skip: 2` 表示每2帧处理1帧）
- 可指定处理区间（起始帧号、结束帧号）

**步骤5：时间戳精确同步**
- 对每一帧视频，找到时间最接近的位姿数据
- 同步算法：最近邻匹配
- 同步精度：时间差<100ms
- 如无法匹配则跳过该帧

**步骤6：YOLO目标检测**
- 将视频帧输入YOLOv11x模型
- 检测11类违规目标：
  1. Buildings（违法建筑）
  2. Vegetation（违规植被）
  3. Sheds（临时棚屋）
  4. Landfills（垃圾堆放）
  5. Illegal Structures（违建）
  6. Storage Zones（违规堆放区）
  7. Cars（违规停车）
  8. Waterways（河道侵占）
  9. Roads（违规道路）
  10. Farmland（违规耕种）
  11. Bareground（裸露地面）
- 对检测结果按置信度筛选（默认>0.25）

**步骤7：坐标转换**
- 基于相机针孔成像模型
- 计算地面分辨率GSD（Ground Sample Distance）
  ```
  GSD = (传感器尺寸 / 图像分辨率) × (飞行高度 / 焦距)
  ```
- 将检测框像素坐标转换为地理偏移
- 结合无人机GPS坐标，计算目标GPS坐标
- 输出检测框四个角点和中心点的经纬度

**步骤8：结果输出**
- 生成CSV文件，包含所有检测记录
- 保存每个检测目标的截图（全帧标注或裁剪图）
- 记录详细处理日志

#### 启动命令

```bash
# 方法1：Windows批处理脚本（推荐）
run_video.bat "data\input\videos\石马河巡检_20260212.MP4"

# 方法2：Python脚本
python run_offline.py "data/input/videos/石马河巡检_20260212.MP4"

# 方法3：完整命令行
python -m src.main --mode offline --video "视频路径.MP4" --config config/offline_config.yaml
```

---

### 3.2 实时流处理流程（用于现场巡检）

#### 流程图

```
[准备阶段] 系统配置
    ├── 配置无人机RTSP视频流地址
    ├── 配置MQTT服务器连接参数
    └── 配置无人机SN序列号
         ↓
[启动阶段] 连接建立
    ├── 连接RTSP视频流
    ├── 连接MQTT消息服务器
    └── 订阅无人机位姿数据主题
         ↓
[运行阶段] 实时处理循环
    │
    ├─> [接收视频帧] ──┐
    │                  │
    ├─> [接收位姿数据] ─┤
    │                  │
    │   [数据同步队列] <┘
    │         ↓
    │   [YOLO检测]
    │         ↓
    │   [坐标转换]
    │         ↓
    │   [实时输出] ──> CSV追加 + 截图保存
    │         ↓
    └─── [可视化显示] ──> 屏幕实时展示
         ↓
[停止阶段] 安全退出
    └── 按Ctrl+C或Esc键停止
    └── 关闭连接，保存最终结果
```

#### 详细步骤说明

**准备阶段：配置参数**

编辑 `config/realtime_config.yaml`：

1. **RTSP视频流配置**
   ```yaml
   rtsp:
     url: "rtsp://192.168.1.100:8554/live"  # 修改为实际地址
     reconnect_interval: 5                   # 断线重连间隔
     timeout: 10                             # 连接超时时间
   ```

2. **MQTT位姿数据配置**
   ```yaml
   mqtt:
     broker: "mqtt.dji.com"
     port: 1883
     username: "实际用户名"
     password: "实际密码"
     topics:
       aircraft_state: "thing/product/{SN号}/state"  # 替换SN号
   ```

**运行阶段：实时处理**

1. 系统连接RTSP视频流和MQTT服务器
2. 实时接收视频帧和位姿数据
3. 将视频帧和位姿数据放入同步队列
4. 按时间戳匹配帧和位姿（最大时间差200ms）
5. 对匹配成功的帧进行YOLO检测
6. 转换坐标并实时输出到CSV
7. 实时显示检测画面和GPS信息

**停止阶段：安全退出**

- 按 `Ctrl+C` 或窗口中按 `Esc` 键
- 系统自动关闭RTSP和MQTT连接
- 保存最终CSV文件和所有截图

#### 启动命令

```bash
# 激活Python环境
conda activate drone_inspection

# 启动实时处理
python run_realtime.py

# 或使用完整命令
python -m src.main --mode realtime --config config/realtime_config.yaml
```

---

### 3.3 OCR备用模式（无SRT字幕时使用）

#### 适用场景

- 视频文件不包含SRT字幕轨道
- 无法从视频中提取字幕数据
- 实时模式下MQTT数据不可用

#### 工作原理

```
视频帧 → 裁剪OSD区域 → PaddleOCR文字识别 → 正则表达式解析 → 提取GPS/高度
```

#### 配置方法

编辑 `config/offline_config.yaml`：

```yaml
ocr:
  enabled: true              # 启用OCR
  engine: "paddleocr"        # OCR引擎
  language: "ch"             # 语言（ch=中文，en=英文）
  
  roi:                       # 感兴趣区域（OSD位置）
    x: 0                     # 左边距
    y: 0                     # 上边距
    width: 800               # 宽度（建议800像素以捕获完整数据）
    height: 300              # 高度
  
  frame_interval: 5          # 每5帧识别一次
  use_gpu: false             # 是否使用GPU加速
```

#### 性能对比

| 指标 | SRT模式 | OCR模式 |
|------|---------|---------|
| 准确度 | ★★★★★ | ★★★★☆ |
| 速度 | ★★★★★ | ★★★☆☆ |
| GPU占用 | 低 | 中 |
| 推荐场景 | 优先推荐 | 备用方案 |

---

## 四、核心技术实现

### 4.1 坐标转换算法

#### 算法原理

检测目标的GPS坐标计算基于针孔相机成像模型和地理投影算法：

**步骤1：计算地面分辨率（GSD）**

```
GSD_x = (传感器宽度 / 图像宽度) × (飞行高度 / 焦距)
GSD_y = (传感器高度 / 图像高度) × (飞行高度 / 焦距)
```

参数说明：
- 传感器尺寸：13.2mm × 8.8mm（1/1.3英寸）
- 图像分辨率：5472 × 3648像素
- 焦距：8.8mm
- 飞行高度：从SRT/MQTT获取（单位：米）

**步骤2：计算像素偏移**

```
像素偏移_x = 检测框中心X - 图像中心X
像素偏移_y = 检测框中心Y - 图像中心Y
```

**步骤3：转换为地理偏移**

```
地理偏移_x(米) = 像素偏移_x × GSD_x
地理偏移_y(米) = 像素偏移_y × GSD_y
```

**步骤4：计算目标GPS坐标**

```
目标经度 = 无人机经度 + 地理偏移_x / 每度经度对应米数
目标纬度 = 无人机纬度 + 地理偏移_y / 每度纬度对应米数
```

其中：
- 每度纬度 ≈ 110,540米
- 每度经度 ≈ 111,320米 × cos(纬度)

**步骤5：计算检测框四角点坐标**

对检测框的左上、右上、右下、左下四个角点分别重复步骤2-4，得到四个角点的GPS坐标。

#### 精度影响因素

| 因素 | 影响程度 | 改善方法 |
|------|---------|---------|
| 相机参数准确性 | ★★★★★ | 使用官方规格或EXIF数据 |
| 飞行高度测量 | ★★★★☆ | 气压高度+RTK差分修正 |
| 时间同步精度 | ★★★☆☆ | 使用SRT而非OCR |
| 无人机姿态稳定 | ★★★☆☆ | 飞行时保持水平 |
| 地面坡度 | ★★☆☆☆ | 适用于平坦地形 |

### 4.2 目标检测算法

#### YOLOv11x模型特点

- **架构**：基于YOLOv8改进的高精度版本
- **输入尺寸**：1280×1280（可配置640-1920）
- **检测类别**：11类水利四乱违规目标
- **推理速度**：GPU模式约30-40ms/帧
- **置信度阈值**：默认0.25（可调整0.1-0.9）

#### 检测流程

```
输入图像 → 预处理（缩放、归一化） → YOLOv11x网络 → 
目标框+置信度 → NMS去重 → 类别筛选 → 输出检测结果
```

#### 参数调优建议

| 需求 | 参数调整 |
|------|---------|
| 提高检出率 | 降低 `confidence_threshold` 到 0.15-0.20 |
| 减少误报 | 提高 `confidence_threshold` 到 0.4-0.6 |
| 提高速度 | 降低 `imgsz` 到 640 |
| 提高精度 | 提高 `imgsz` 到 1920（需更多显存） |

### 4.3 时间同步机制

#### 同步策略

**离线视频模式**：
- 精确时间戳匹配
- SRT字幕时间码与视频帧时间戳对齐
- 容差：<100ms

**实时流模式**：
- 最近邻匹配
- 视频帧时间戳与MQTT位姿消息时间戳对比
- 容差：<200ms

#### 同步算法

```python
def find_closest_pose(frame_timestamp, pose_buffer):
    """查找最接近的位姿数据"""
    min_diff = float('inf')
    best_pose = None
    
    for pose in pose_buffer:
        time_diff = abs(frame_timestamp - pose.timestamp)
        if time_diff < min_diff and time_diff < 200:  # 200ms容差
            min_diff = time_diff
            best_pose = pose
    
    return best_pose if best_pose else None
```

---

## 五、输出结果说明

### 5.1 CSV结构化报告

#### 文件路径

- 离线模式：`data/output/csv/detections_offline.csv`
- 实时模式：`data/output/csv/detections_realtime.csv`

#### 字段说明

| 列名 | 数据类型 | 说明 | 示例值 |
|------|---------|------|--------|
| timestamp | 浮点数 | Unix时间戳（毫秒） | 1770186401669.089 |
| frame_number | 整数 | 视频帧序号 | 123 |
| datetime | 字符串 | 日期时间 | 2026-02-12 10:30:15.123 |
| class_id | 整数 | 目标类别ID | 1 |
| class_name | 字符串 | 目标类别名称 | "Vegetation"（违规植被） |
| confidence | 浮点数 | 检测置信度 | 0.8327 |
| **corner1_lat** | 浮点数 | 检测框左上角纬度 | 22.779961 |
| **corner1_lon** | 浮点数 | 检测框左上角经度 | 114.101265 |
| **corner2_lat** | 浮点数 | 检测框右上角纬度 | 22.779961 |
| **corner2_lon** | 浮点数 | 检测框右上角经度 | 114.101373 |
| **corner3_lat** | 浮点数 | 检测框右下角纬度 | 22.779668 |
| **corner3_lon** | 浮点数 | 检测框右下角经度 | 114.101373 |
| **corner4_lat** | 浮点数 | 检测框左下角纬度 | 22.779668 |
| **corner4_lon** | 浮点数 | 检测框左下角经度 | 114.101265 |
| **center_lat** | 浮点数 | 目标中心纬度 | 22.779814 |
| **center_lon** | 浮点数 | 目标中心经度 | 114.101319 |
| altitude | 浮点数 | 无人机飞行高度（米） | 139.231 |
| drone_lat | 浮点数 | 无人机当前纬度 | 22.779954 |
| drone_lon | 浮点数 | 无人机当前经度 | 114.100891 |
| image_path | 字符串 | 检测截图文件路径 | ./data/output/images/... |

#### 数据特点

- **CGCS2000坐标系**：所有经纬度坐标均采用中国国家标准CGCS2000坐标系（EPSG:4490）
- **坐标转换**：DJI无人机GPS原始坐标为WGS84，系统自动转换为CGCS2000，转换精度优于0.1米
- **四角点定位**：提供检测框完整的四个角点坐标，可精确标注目标范围
- **中心点坐标**：提供目标中心GPS坐标，方便快速定位
- **完整溯源**：记录帧号、时间戳、无人机位置，可完整追溯

### 5.2 检测截图

#### 文件命名规则

```
格式：frame_帧号_obj_序号_类别名_时间戳.jpg

示例：
frame_000123_obj_001_Vegetation_20260212_103015_456.jpg
frame_000124_obj_001_Sheds_20260212_103016_123.jpg
```

#### 图片内容

- **完整帧画面**：包含无人机拍摄的完整视频帧
- **检测框标注**：用矩形框标出违规目标位置
- **类别和置信度**：框上方显示目标类别和置信度分数
- **高分辨率**：保持原视频分辨率（5472×3648）

#### 存储位置

- 离线模式：`data/output/images/offline/`
- 实时模式：`data/output/images/realtime/`

### 5.3 GeoJSON地理数据

#### 生成方法

```bash
python tools/export_to_geojson.py data/output/csv/detections_offline.csv --min-confidence 0.5
```

#### 输出文件

- `data/output/detections.geojson` - 所有检测目标
- `data/output/detections_high_conf.geojson` - 高置信度检测（>0.5）

#### 数据格式

```json
{
  "type": "FeatureCollection",
  "features": [
    {
      "type": "Feature",
      "geometry": {
        "type": "Polygon",
        "coordinates": [[
          [114.101265, 22.779961],  // 角点1
          [114.101373, 22.779961],  // 角点2
          [114.101373, 22.779668],  // 角点3
          [114.101265, 22.779668],  // 角点4
          [114.101265, 22.779961]   // 闭合
        ]]
      },
      "properties": {
        "class_name": "Vegetation",
        "confidence": 0.8327,
        "datetime": "2026-02-12 10:30:15",
        "image_path": "frame_000123_obj_001_Vegetation_20260212_103015.jpg"
      }
    }
  ]
}
```

#### 应用场景

- 导入QGIS进行专业地理分析
- 导入ArcGIS进行空间统计
- 转换为KML格式在Google Earth中查看
- 用于Web地图（Leaflet、OpenLayers）展示

### 5.4 交互式Web地图

#### 生成方法

```bash
python tools/quick_visualize.py
# 自动打开浏览器显示 data/output/map.html
```

#### 功能特点

- **底图显示**：使用OpenStreetMap街道地图
- **目标标注**：在地图上显示所有检测框
- **颜色分类**：不同类别用不同颜色标识
- **交互查询**：点击目标查看详细信息（类别、置信度、坐标）
- **自动缩放**：自动定位到检测区域并适配显示范围
- **图片预览**：点击目标可查看检测截图

---

## 六、操作指南

### 6.1 环境准备

#### 系统要求

| 项目 | 要求 |
|------|------|
| 操作系统 | Windows 10/11 或 Ubuntu 18.04+ |
| Python版本 | 3.8 - 3.10 |
| GPU（推荐） | NVIDIA显卡，CUDA 11.8+ |
| 内存 | 建议16GB以上 |
| 磁盘空间 | 至少50GB可用空间 |

#### 安装步骤

```bash
# 1. 创建Python环境
conda create -n drone_inspection python=3.9 -y
conda activate drone_inspection

# 2. 安装依赖包
pip install -r requirements.txt

# 3. 安装FFmpeg（Windows）
choco install ffmpeg -y
# 或从官网下载：https://ffmpeg.org/download.html

# 4. 验证安装
python -c "import torch; print(f'PyTorch: {torch.__version__}, CUDA: {torch.cuda.is_available()}')"
ffmpeg -version
```

#### 模型文件准备

将训练好的YOLOv11x模型文件放入 `models/` 目录：

```
models/
└── yolov11x.pt  # 确保此文件存在
```

### 6.2 配置文件调整

#### 相机参数配置（重要）

编辑 `config/camera_params.yaml`：

```yaml
camera:
  model: "M4TD"                    # 无人机相机型号
  resolution:
    width: 5472                    # ⚠️ 必须与实际拍摄分辨率一致
    height: 3648
  sensor_size:
    width: 13.2                    # ⚠️ 传感器物理尺寸（mm）
    height: 8.8
  focal_length: 8.8                # ⚠️ 镜头焦距（mm）
```

> **重要提示**：这些参数直接影响GPS坐标精度！必须根据实际无人机参数配置。

#### 检测参数配置

编辑 `config/yolo_config.yaml`：

```yaml
model:
  device: "cuda"                   # cuda=使用GPU，cpu=使用CPU
  
detection:
  confidence_threshold: 0.25       # 置信度阈值（越低检出越多）
  iou_threshold: 0.45              # NMS去重阈值
  imgsz: 1280                      # 推理图像尺寸（越大越精确但越慢）
```

#### 离线处理配置

编辑 `config/offline_config.yaml`：

```yaml
input:
  frame_skip: 2                    # 跳帧数（2=每2帧处理1帧）
  
output:
  save_images: true                # 是否保存检测截图
  image_format: "full"             # full=全帧，crop=仅目标区域
  
visualization:
  realtime_display: true           # 是否实时显示处理画面
```

### 6.3 典型使用场景

#### 场景1：处理单个视频文件

```bash
# Windows用户（推荐）
run_video.bat "data\input\videos\石马河巡检_20260212.MP4"

# Linux/Mac用户
python run_offline.py "data/input/videos/石马河巡检_20260212.MP4"
```

**处理流程**：
1. 系统自动提取SRT字幕（或启用OCR）
2. 逐帧检测违规目标
3. 生成CSV报告和截图
4. 显示处理进度和统计信息

**预期输出**：
```
[INFO] 开始处理视频: 石马河巡检_20260212.MP4
[INFO] 视频信息: 25fps, 5472x3648, 时长: 10分32秒
[INFO] 提取SRT字幕成功
[INFO] 处理进度: 100% [1580/1580帧]
[INFO] 检测到目标: 45个
[INFO] 输出CSV: data/output/csv/detections_offline.csv
[INFO] 保存截图: 45张
[INFO] 处理完成，耗时: 8分15秒
```

#### 场景2：批量处理多个视频

创建批处理脚本 `batch_process.bat`：

```batch
@echo off
for %%f in (data\input\videos\*.MP4) do (
    echo 处理: %%f
    python run_offline.py "%%f"
)
echo 批量处理完成！
pause
```

#### 场景3：实时巡检监控

```bash
# 1. 配置RTSP和MQTT参数
# 编辑 config/realtime_config.yaml

# 2. 启动实时处理
python run_realtime.py

# 3. 观察实时输出
# 系统会在屏幕上显示检测画面和GPS信息
# 检测结果实时追加到CSV文件

# 4. 按Ctrl+C停止
```

#### 场景4：查看处理结果

```bash
# 生成交互式地图
python tools/quick_visualize.py
# 自动在浏览器中打开地图

# 导出GeoJSON格式（用于GIS软件）
python tools/export_to_geojson.py data/output/csv/detections_offline.csv

# 生成汇总报告
python tools/generate_report.py --csv data/output/csv/detections_offline.csv
```

---

## 七、质量控制与验证

### 7.1 结果验证流程

#### 自动验证脚本（推荐）

```bash
run_validation.bat
```

该脚本自动完成：
1. ✓ 导出GeoJSON格式
2. ✓ 在浏览器中打开交互式地图
3. ✓ 生成统计报告
4. ✓ 输出验证日志

#### 手动验证步骤

**步骤1：数据完整性检查**

```bash
# 检查CSV文件
- 打开 data/output/csv/detections_offline.csv
- 确认数据列完整
- 检查是否有空值或异常值
- 统计检测数量
```

**步骤2：地理坐标验证**

```bash
# 在地图上查看
python tools/quick_visualize.py

# 验证要点：
- 检测目标是否位于石马河流域范围内
- GPS坐标是否合理（纬度22-23°，经度113-115°）
- 目标位置是否与视频画面匹配
```

**步骤3：检测精度评估**

```bash
# 抽样验证（建议抽取10-20个样本）
1. 随机选择检测结果
2. 打开对应的截图文件
3. 人工判断检测是否正确
4. 记录误报率和漏报率
```

### 7.2 精度评估指标

#### 目标检测精度

| 指标 | 计算方法 | 目标值 |
|------|---------|--------|
| 准确率（Precision） | 正确检测数 / 总检测数 | >85% |
| 召回率（Recall） | 正确检测数 / 实际目标数 | >80% |
| 置信度均值 | 所有检测的平均置信度 | >0.6 |

#### 定位精度

| 指标 | 测量方法 | 目标值 |
|------|---------|--------|
| GPS坐标误差 | 与实际位置比对 | <5米 |
| 角点坐标一致性 | 四角点是否形成合理矩形 | 100% |
| 时间同步精度 | 帧与位姿的时间差 | <100ms |

### 7.3 常见问题处理

#### 问题1：检测数量过少

**可能原因**：
- 置信度阈值设置过高
- 目标类别过滤设置错误
- 视频质量不佳

**解决方案**：
1. 降低置信度阈值：`confidence_threshold: 0.15`
2. 检查类别过滤：`target_classes: null`（不过滤）
3. 检查视频清晰度和光照条件

#### 问题2：检测误报过多

**可能原因**：
- 置信度阈值设置过低
- 模型训练数据与实际场景差异大

**解决方案**：
1. 提高置信度阈值：`confidence_threshold: 0.5`
2. 后处理筛选：只保留高置信度结果
3. 人工复核：对低置信度检测进行二次确认

#### 问题3：GPS坐标偏差较大

**可能原因**：
- 相机参数配置错误
- 飞行高度数据不准确
- 时间同步失败

**排查步骤**：
1. 验证 `camera_params.yaml` 中的参数
2. 检查SRT/MQTT中的高度数据
3. 查看日志中的时间同步误差
4. 使用已知地标进行标定

**临时修正方法**：
```python
# 如发现系统性偏差，可添加修正量
# 在 coord_transform.py 中：
target_lon = target_lon - 0.00045  # 向西修正约50米
target_lat = target_lat + 0.00036  # 向北修正约40米
```

---

## 八、系统性能

### 8.1 处理速度

| 硬件配置 | 处理模式 | 视频分辨率 | 处理速度 |
|---------|---------|-----------|---------|
| RTX 3050 6GB | 离线（跳帧2） | 5472×3648 | 约2倍速 |
| RTX 3050 6GB | 离线（逐帧） | 5472×3648 | 约0.8倍速 |
| RTX 3050 6GB | 实时流 | 1920×1080 | 实时（25fps） |
| CPU Only | 离线（跳帧5） | 5472×3648 | 约0.3倍速 |

**注**：2倍速表示处理10分钟视频需要5分钟。

### 8.2 资源占用

| 资源类型 | 占用量 | 说明 |
|---------|-------|------|
| GPU显存 | 4-6GB | YOLOv11x推理 + 视频解码 |
| 内存 | 8-12GB | 视频缓冲 + 数据队列 |
| 磁盘空间 | 约100MB/分钟视频 | 截图存储（取决于检测数量） |
| CPU使用率 | 30-50% | 视频解码和数据处理 |

### 8.3 优化建议

#### 提高处理速度

1. **启用跳帧**：`frame_skip: 3-5`（适合目标移动缓慢的场景）
2. **降低推理尺寸**：`imgsz: 640`（略微降低精度换取速度）
3. **关闭实时显示**：`realtime_display: false`
4. **关闭截图保存**：`save_images: false`（仅需要CSV数据时）
5. **启用半精度推理**：`half_precision: true`（需要支持FP16的GPU）

#### 降低资源占用

1. **减少缓冲区**：`max_queue_size: 10`
2. **裁剪截图**：`image_format: "crop"`（仅保存目标区域）
3. **限制帧率**：`frame_interval: 2`（实时模式）

---

## 九、项目交付

### 9.1 交付物清单

#### 源代码

- [ ] `src/` 目录完整源代码
- [ ] `config/` 配置文件（已调整为石马河实际参数）
- [ ] `tools/` 验证和可视化工具脚本
- [ ] `run_*.py` 和 `run_*.bat` 快捷启动脚本

#### 模型文件

- [ ] `models/yolov11x.pt` 训练好的检测模型

#### 文档资料

- [ ] `README.md` 项目主文档
- [ ] `README_VIDEO.md` 视频处理详细文档
- [ ] 本报告：《石马河四乱检测流程与步骤报告》
- [ ] `docs/DJI_MQTT_SETUP.md` 无人机配置指南

#### 测试数据（可选）

- [ ] 示例视频文件（石马河巡检视频）
- [ ] 示例SRT字幕文件
- [ ] 示例处理结果（CSV、截图、GeoJSON）

### 9.2 环境配置说明

**开发环境记录**：
```
操作系统：Windows 11 专业版
Python版本：3.9.13
CUDA版本：11.8
GPU型号：NVIDIA RTX 3050 6GB
conda环境名：drone_inspection

关键依赖版本：
- torch: 2.1.0+cu118
- ultralytics: 8.0.220
- opencv-python: 4.8.1
- paddleocr: 2.7.3
- paho-mqtt: 1.6.1
- pandas: 2.0.3
```

### 9.3 操作培训要点

#### 必须掌握的操作

1. ✓ 如何处理一个视频文件（从导入到查看结果）
2. ✓ 如何调整置信度阈值
3. ✓ 如何查看CSV结果和地图
4. ✓ 如何判断检测结果的准确性
5. ✓ 常见错误的排查方法

#### 建议掌握的操作

1. 如何修改相机参数
2. 如何配置实时流模式
3. 如何批量处理多个视频
4. 如何导出GeoJSON供其他软件使用

---

## 十、总结

### 10.1 系统优势

1. **高度自动化**：从视频输入到GPS坐标输出全程自动处理
2. **精确定位**：基于相机成像模型的米级定位精度
3. **灵活部署**：支持离线和实时两种工作模式
4. **结果可视化**：提供CSV、截图、地图等多种输出格式
5. **易于使用**：一键启动脚本，无需复杂命令
6. **可扩展性**：支持模型更新和参数调优

### 10.2 适用范围

- ✅ 河道"四乱"问题巡检（违建、垃圾、植被、侵占）
- ✅ 水利工程巡查（堤防、闸站、水库）
- ✅ 环境监测（污染源、生态破坏）
- ✅ 土地利用监测（违法占地、违规建设）

### 10.3 未来改进方向

1. **提高精度**：引入RTK差分定位，进一步提高GPS精度
2. **增强检测**：扩展检测类别，支持更多违规类型
3. **实时预警**：实时模式下检测到违规立即发送告警
4. **移动端支持**：开发手机App，现场即时查看结果
5. **数据库集成**：将检测结果直接存入数据库系统
6. **AI辅助决策**：基于历史数据进行趋势分析和预测

---

## 附录

### 附录A：配置文件示例

#### camera_params.yaml
```yaml
camera:
  model: "M4TD"
  resolution:
    width: 5472
    height: 3648
  sensor_size:
    width: 13.2
    height: 8.8
  focal_length: 8.8
  principal_point:
    cx: 2736
    cy: 1824

earth:
  meters_per_degree_lat: 110540
  meters_per_degree_lon: 111320
```

#### yolo_config.yaml
```yaml
model:
  path: "./models/yolov11x.pt"
  device: "cuda"
  half_precision: false

detection:
  confidence_threshold: 0.25
  iou_threshold: 0.45
  imgsz: 1280
  target_classes: null

classes:
  names:
    0: "Buildings"
    1: "Vegetation"
    2: "Cars"
    3: "Roads"
    4: "Waterways"
    5: "Farmland"
    6: "Bareground"
    7: "Landfills"
    8: "Sheds"
    9: "Storage Zones"
    10: "Illegal Structures"
```

### 附录B：常用命令速查

| 操作 | 命令 |
|------|------|
| 处理视频 | `run_video.bat "视频路径.MP4"` |
| 实时巡检 | `python run_realtime.py` |
| 生成地图 | `python tools/quick_visualize.py` |
| 导出GeoJSON | `python tools/export_to_geojson.py data/output/csv/detections_offline.csv` |
| 验证结果 | `run_validation.bat` |
| 查看GPU状态 | `nvidia-smi` |
| 激活环境 | `conda activate drone_inspection` |

### 附录C：联系方式

**项目负责人**：[填写姓名]  
**联系电话**：[填写电话]  
**电子邮箱**：[填写邮箱]  
**技术支持**：参考本报告及README.md文档

---

**报告编制**：无人机巡检系统开发团队  
**系统版本**：v2.0.0  
**报告日期**：2026年2月12日  
**适用项目**：石马河四乱检测系统
